# NLP and Deep Learning All-in-One Part I: RNN and LSTM
Recurrent Based Models Interview Questions
1. What is Recurrent Neural Network (RNN)?
2. How to train RNN?
3. What are the Advantages of RNN?
4. What are the Disadvantages of RNN?
5. What is Gradient Vanishing and Exploding Problem?
6. What are some the general ways to handle the vanishing gradient problem?
7. What is Long Short-Term Memory (LSTM)?
8. What is Cell State?
9. What is Gating Mechanism?
10. How to update cell state?
11. How does LSTMs forget gate structure avoid vanishing gradient? how does the forget gate manipulate these internal vectors?
12. What is a Batch? What is an Epoch? Whatâ€™s the difference?
13. How to choose the Number of Hidden Layers?
14. How to choose the Number of Neurons in the Hidden Layers?
15. What is Dropout?

<div align="center">
<img width="1337" alt="WechatIMG3528" src="https://user-images.githubusercontent.com/31713746/198068277-91547504-4fd3-411c-ad9e-e0b96ea96c82.png">
</div>
