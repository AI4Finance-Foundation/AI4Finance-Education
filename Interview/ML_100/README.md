# 100 Practical Machine Learning Questions to Crack the Phone Interview

Machine Learning Interview Questions
1. What is Bias-Variance Tradeoff?
2. What is the curse of dimensionality?
3. What is Multi-Collinearity? Why is it an issue?
4. How do you detect multicollinearity in Model Data?
5. What are the remedies of problem of Multi-collinearity?
6. What are Outliers? Leverage & Influential points?
7. How can we deal with Outliers?
8. If you have set of data and do regression, what if you duplicate all the data and do regression on the new data set?
9. What is the primary difference between R square and adjusted R square?
10. What’s Gradient Descent?
11. How to implement Gradient Descent?
12. What’s the difference between confidence interval and predicted interval?
13. Why do you need Cross-Validation?
14. How to detect overfitting?
15. How do you handle overfitting problem?
16. How to handle missing data?
17. You have a train-set, a dev-set and a test-set, how did you manage the distribution of those sets?
18. How to handle imbalanced data?
19. What are the methods for over-sampling?
20. What is Confusion Matrix? What’s TP, TN, FP, FN, Precision and Recall?
21. What is ROC and AUC?
22. How to handle categorical variables?
23. What is the difference between Generative models and Discriminative models?
24. What is linear regression? What are the steps of the algorithm?
25. What are the assumptions of linear regression?
26. What plot is best suited to test the linear relationship of independent and dependent continuous variables?
27. Let’s assume that the errors break the normality assumption, it’s not a Gaussian distribution, can you still use linear regression?
28. What is the cost function of linear regression?
29. How do you interpret a Q-Q plot in a linear regression model?
30. What is the importance of the F-test in a linear model?
31. What are the Advantages/Disadvantages of linear regression?
32. What is regularization?
33. What’s the difference between Lasso and Ridge? What’s the cost function?
34. Why does Lasso can make coefficients to 0 but Ridge can’t?
35. What is lambda λ in Lasso?
36. What are the Advantages/Disadvantages of Lasso and Ridge?
37. What’s Logistic Regression? How to implement Logistic Regression?
38. What’s the cost function of logistic regression?
39. What does Cross-Entropy measure?
40. What’s an Entropy?
41. How to tune hyperparameters of logistic regression? What does the parameter mean?
42. What are the Advantages/Disadvantages of Logistic Regression?
43. What are the basic concepts of Naïve Bayes? What problem does it solve?
44. What are the assumptions of Naïve Bayes?
45. What is Bayes’ Theorem?
46. How to implement Naïve Bayes?
47. What are the Advantages/Disadvantages of Naïve Bayes?
48. What are the variations of Naïve Bayes?
49. What are the applications of NaïveBayes?
50. What’s KNN? How to implement KNN?
51. What are the Advantages/Disadvantages of KNN?
52. What’s K-means?
53. How to implement K-means?
54. How to choose K?
55. How to evaluate clusters?
56. When to stop the iteration?
57. How to do categorical data clustering?
58. What about a data set considering both numerical and categorical values?
59. What are the Advantages/Disadvantages of K-means?
60. What’s Decision Tree?
61. How to implement Classification Tree? What if the features are categorical values? What if the features are numerical values?
62. How to implement Regression Tree?
63. How to decide which feature is more important? What should be at the top of our decision tree? The root node?
64. When to stop splitting?
65. What is tree pruning?
66. What metrices to use to evaluate classification tree?
67. What are the Advantages/Disadvantages of Decision Tree?
68. What’s Random Forest? How to implement Random Forest?
69. Why randomly restrict the features in each split? Build a random forest at each split the algorithm is not allowed to consider a majority of the available predictors. Why?
70. What’s the difference between bagging and boosting?
71. How to tune hyperparameters of Random Forest?
72. What are the Advantages/Disadvantages of Random Forest?
73. What’s Ada-boost? How to implement Ada-boost?
74. Why use exponential function as loss function?
75. What are the Advantages/Disadvantages of Ada-boost?
76. What’s Gradient Boosting? How to implement Gradient Boosting?
77. What are the Advantages/Disadvantages of Gradient Boosting?
78. What’s the difference between XGBoost and GBM?
79. What’s Support Vector Machine (SVM)? How to implement SVM?
80. What’s Kernel Trick?
81. What’s the cost function of SVM?
82. What are the Advantages/Disadvantages of SVM?
83. What’s PCA? How to implement PCA?
84. What is the truncation of PCA?
85. How would you choose the value of K? The eigenvectors you will take to next stage?
86. What are the Advantages/Disadvantages of PCA?
87. What are the basic concepts of Neural Network?
88. How to implement Neural Network? What’s feedforward? What’s backpropagation?
89. What’s the cost function of Neural Network?
90. What are the activation functions of Neural Network?
91. What are the Advantages/Disadvantages of Neural Network?



<div align="center">
<img width="688" alt="WechatIMG3523" src="https://user-images.githubusercontent.com/31713746/198067728-bdb3dd2c-ef32-42e9-aff9-e3dbefdd0407.png">
</div>
